---
title: "Covariates selection"
author:
  - Bénédicte Colnet [Inria, Paris-Saclay]
date: "October 2021"
output:
  html_document:
    code_folding: "hide"
    number_sections: no
    toc: yes
    toc_depth: 2
  pdf_document:
    toc: yes
   
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Reproducibility
set.seed(123)

# Libraries
library(dplyr) # case_when and others
library(ggplot2)
library(tidyr) # pivot
library(grf)
library(glmnet)
library(ranger) # efficient forest
library(splines) # function bs() for splines
library(mvtnorm) # rmvnorm
library(tmle)
library(SuperLearner)

source("estimators.R")
source("generate_data_models.R")
```


```{r}
a_simulation <- generate_simulation_linear_constant_cate()
```


```{r}
# Custom AIPW with super learning for nuisance parameters
aipw_ML <- function(covariates_names_vector_treatment,
                    covariates_names_vector_outcome,
                    dataframe,
                    outcome_name = "Y",
                    treatment_name = "A",
                    n.folds = 2){
  
  n_obs <- nrow(dataframe)
  
  # Fit elastic net with 5 different alphas: 0, 0.2, 0.4, 0.6, 0.8, 1.0.
  # 0 corresponds to ridge and 1 to lasso.
  enet = create.Learner("SL.glmnet", detailed_names = T,
                        tune = list(alpha = seq(0, 1, length.out = 5)))
  
  # Choose libraries for our super learner
  sl_libs_outcome <- c('SL.glmnet', 'SL.ranger', 'SL.earth', 'SL.glm', 'SL.mean', "SL.bartMachine", "SL.xgboost", enet$names)
  sl_libs_treatment <- c('SL.glmnet', 'SL.ranger', 'SL.earth', 'SL.glm', 'SL.mean', "SL.bartMachine", "SL.xgboost", enet$names)
  
  # Cross-fitted estimates of E[Y|X,W=1], E[Y|X,W=0] and e(X) = P[W=1|X]
  mu.hat.1 <- rep(NA, n_obs)
  mu.hat.0 <- rep(NA, n_obs)
  e.hat <- rep(NA, n_obs)
  
  # Useful quantities for afterward
  Y <- dataframe[,outcome_name]
  W <- dataframe[,treatment_name]
  X <- dataframe[,covariates_names_vector_treatment]

  
  if (n.folds > 1){
    
    indices <- split(seq(n_obs), sort(seq(n_obs) %% n.folds))
    
    for (idx in indices) {
      
    X_treated <- dataframe[-idx & dataframe[,treatment_name] == 1, covariates_names_vector_outcome]
    Y_treated <- dataframe[-idx & dataframe[,treatment_name] == 1, outcome_name]
    X_control <- dataframe[-idx & dataframe[,treatment_name] == 0, covariates_names_vector_outcome]
    Y_control <- dataframe[-idx & dataframe[,treatment_name] == 0, outcome_name]
    
    # Fit super learner on the set -idx
    mu.1.model <- SuperLearner(Y = Y_treated, 
                  X = X_treated, 
                  family = gaussian(), 
                  SL.library = sl_libs_outcome) 
        
    mu.0.model <- SuperLearner(Y = Y_control, 
                  X = X_control, 
                  family = gaussian(), 
                  SL.library = sl_libs_outcome) 
      
    propensity.model <- SuperLearner(Y = Y[-idx], 
                  X = X[-idx,], 
                  family = binomial(), 
                  SL.library = sl_libs_treatment) 
    
    # Predict with cross-fitting
    mu.hat.1[idx] <- predict(mu.1.model, 
                               newdata = dataframe[idx,  covariates_names_vector_outcome])$pred
    mu.hat.0[idx] <- predict(mu.0.model, 
                               newdata = dataframe[idx,  covariates_names_vector_outcome])$pred
    e.hat[idx] <- predict(propensity.model, 
                            newdata = dataframe[idx, covariates_names_vector_treatment])$pred
      
    }
  } else if (n.folds == 0 | n.folds == 1){
    
    X_treated <- dataframe[dataframe[,treatment_name] == 1, covariates_names_vector_outcome]
    Y_treated <- dataframe[dataframe[,treatment_name] == 1, outcome_name]
    X_control <- dataframe[dataframe[,treatment_name] == 0, covariates_names_vector_outcome]
    Y_control <- dataframe[dataframe[,treatment_name] == 0, outcome_name]
      
    
    # Fit super learner
    mu.1.model <- SuperLearner(Y = Y_treated, 
                  X = X_treated, 
                  family = gaussian(), 
                  SL.library = sl_libs_outcome) 
        
    mu.0.model <- SuperLearner(Y = Y_control, 
                  X = X_control, 
                  family = gaussian(), 
                  SL.library = sl_libs_outcome) 
      
    propensity.model <- SuperLearner(Y = Y, 
                  X = X, 
                  family = binomial(), 
                  SL.library = sl_libs_treatment) 
      
    # Predict 
    mu.hat.1 <- predict(mu.1.model, newdata = dataframe[,covariates_names_vector_outcome])$pred
    mu.hat.0 <- predict(mu.0.model, newdata = dataframe[, covariates_names_vector_outcome])$pred
    e.hat <- predict(propensity.model, newdata = dataframe[, covariates_names_vector_treatment])$pred

    
  } else {
    stop("n.fold must be a positive integer")
  }

  # replace extreme values if necessary
  e.hat <- replace(e.hat, e.hat < 0.01, 0.01)
  e.hat <- replace(e.hat, e.hat > 0.99, 0.99)  
  
  ## T-learner
  t.learner <- mean(mu.hat.1) - mean(mu.hat.0)
  
  ## AIPW
  aipw <- (mu.hat.1 - mu.hat.0
           + W / e.hat * (Y -  mu.hat.1)
           - (1 - W) / (1 - e.hat) * (Y -  mu.hat.0))
  
  aipw <- mean(aipw)
  
  ## IPW
  ipw = mean(Y * (W/e.hat - (1-W)/(1-e.hat)))
  
  
  res = c("ipw" = ipw, "t.learner" = t.learner, "aipw" = aipw)
  
  return(res)
}
```


```{r}
aipw_ML(paste0("X.", 1:12), paste0("X.", 1:12), dataframe = a_simulation, n.folds = 0)
```








```{r}
a_simulation <- generate_simulation_linear_constant_cate()
# for maximum accuracy one may try glmnet, randomForest, XGBoost, SVM, and bartMachine
sl_lib = c("SL.lm", "SL.mean")
# by default it uses 10 cross fold validation
result = SuperLearner(Y = a_simulation[,"Y"], X = a_simulation[,4:10], SL.library = sl_lib, family = gaussian())
```

```{r}
a_new_simulation <- generate_simulation_linear_constant_cate()
predict(result, a_new_simulation[,4:10], onlySL = TRUE)$pred[1:10,]
```

```{r}
# Doing cross validation 
# This will take about 2x as long as the previous SuperLearner.
cv_sl = CV.SuperLearner(Y = y_train, X = x_train, family = binomial(),
                          # For a real analysis we would use V = 10.
                          cvControl = list(V = 2), innerCvControl = list(list(V=2)),
                          SL.library = c("SL.mean", "SL.glmnet", "SL.ranger"))
```


```{r}
results.linear.indep.cov <- data.frame("sample.size" = c(),
                      "estimate" = c(),
                      "estimator" = c(),
                      "subset" = c(),
                      "simulation" = c())


for (sample.size in c(100, 300, 1000, 3000, 9000)){
  for (i in 1:30){
    # generate a simulation
    
    a_simulation <- generate_simulation_linear_constant_cate(n_obs = sample.size, independent_covariate = TRUE)
      
    # choose subset
    for (method in different_subset_tested){
        if (method == "all.covariates"){
          X_treatment <- paste0("X.", 1:12)
          X_outcome <- paste0("X.", 1:12)
        } else if (method == "all.covariates.wo.instruments"){
          X_treatment <- paste0("X.", 4:12)
          X_outcome <- paste0("X.", 4:12)
        } else if (method == "smart"){
          X_treatment <- paste0("X.", 4:7)
          X_outcome <- paste0("X.", 4:10)
        } else if (method == "minimal.set"){
          X_treatment <- paste0("X.", 4:7)
          X_outcome <- paste0("X.", 4:7)
        } else {
          stop("error in subset.")
        }
        custom_aipw <- aipw_linear(X_treatment, X_outcome, dataframe = a_simulation)

        new.row <- data.frame("sample.size" = rep(sample.size, 3),
                      "estimate" = c(custom_aipw["ipw"],
                                     custom_aipw["t.learner"],
                                     custom_aipw["aipw"]),
                      "estimator" = c("ipw",
                                      "t-learner",
                                      "aipw"),
                      "subset" = rep(method, 3),
                      "simulation" = rep("linear", 3))

        results.linear.indep.cov <- rbind(results.linear.indep.cov, new.row)
    }
  }
}
  
results.linear.indep.cov$sample.size <- as.factor(results.linear.indep.cov$sample.size)
```


```{r}
ggplot(results.linear.indep.cov[results.linear.indep.cov$sample.size != 100 & results.linear.indep.cov$sample.size != 300,], aes(x = sample.size, y = estimate, fill = subset)) +
  geom_boxplot(alpha = 0.8) +
  facet_grid(~estimator, scales = "free") +
  geom_hline(yintercept = 3, color = "darkblue") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5),
        legend.position = "bottom") +
  xlab("Sample size") +
  ylab("") 
```
```{r}
results.linear.indep.cov$covariates <- rep("independent", nrow(results.linear.indep.cov))
results.linear$covariates <- rep("non-independent", nrow(results.linear))
total.linear <- rbind(results.linear.indep.cov, results.linear)
```


```{r}
ggplot(total.linear[total.linear$sample.size != 100 & total.linear$sample.size != 300,], aes(x = sample.size, y = estimate, fill = subset)) +
  geom_boxplot(alpha = 0.8) +
  facet_grid(covariates~estimator, scales = "free") +
  geom_hline(yintercept = 3, color = "darkblue") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5),
        legend.position = "bottom") +
  xlab("Sample size") +
  ylab("")
```



```{r}
results.linear.no.crossfitting <- data.frame("sample.size" = c(),
                      "estimate" = c(),
                      "estimator" = c(),
                      "subset" = c(),
                      "simulation" = c())


for (sample.size in c(1000, 3000, 9000)){
  for (i in 1:30){
    # generate a simulation
    
    a_simulation <- generate_simulation_linear_constant_cate(n_obs = sample.size, independent_covariate = FALSE)
      
    # choose subset
    for (method in different_subset_tested){
        if (method == "all.covariates"){
          X_treatment <- paste0("X.", 1:12)
          X_outcome <- paste0("X.", 1:12)
        } else if (method == "all.covariates.wo.instruments"){
          X_treatment <- paste0("X.", 4:12)
          X_outcome <- paste0("X.", 4:12)
        } else if (method == "smart"){
          X_treatment <- paste0("X.", 4:7)
          X_outcome <- paste0("X.", 4:10)
        } else if (method == "minimal.set"){
          X_treatment <- paste0("X.", 4:7)
          X_outcome <- paste0("X.", 4:7)
        } else {
          stop("error in subset.")
        }
        custom_aipw <- aipw_linear(X_treatment, X_outcome, dataframe = a_simulation, n.folds = 0)

        new.row <- data.frame("sample.size" = rep(sample.size, 3),
                      "estimate" = c(custom_aipw["ipw"],
                                     custom_aipw["t.learner"],
                                     custom_aipw["aipw"]),
                      "estimator" = c("ipw",
                                      "t-learner",
                                      "aipw"),
                      "subset" = rep(method, 3),
                      "simulation" = rep("linear", 3))

        results.linear.no.crossfitting <- rbind(results.linear.no.crossfitting, new.row)
    }
  }
}
  
results.linear.no.crossfitting$sample.size <- as.factor(results.linear.no.crossfitting$sample.size)
```

```{r}
ggplot(results.linear.no.crossfitting, aes(x = sample.size, y = estimate, fill = subset)) +
  geom_boxplot(alpha = 0.8) +
  facet_grid(~estimator, scales = "free") +
  geom_hline(yintercept = 3, color = "darkblue") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 0.5),
        legend.position = "bottom") +
  xlab("Sample size") +
  ylab("") 
```


Friedman ne marche pas bien !!
Prendre plutôt chernozukhov et puis les simu de Wager.

